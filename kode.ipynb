{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"dataset/dickson_liver_cirrhosis.csv\"\n",
    "TARGET_COL = \"Stage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_Days</th>\n",
       "      <th>Status</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ascites</th>\n",
       "      <th>Hepatomegaly</th>\n",
       "      <th>Spiders</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Alk_Phos</th>\n",
       "      <th>SGOT</th>\n",
       "      <th>Tryglicerides</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Prothrombin</th>\n",
       "      <th>Stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2221</td>\n",
       "      <td>C</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>18499</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.5</td>\n",
       "      <td>149.0</td>\n",
       "      <td>4.04</td>\n",
       "      <td>227.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>52.70</td>\n",
       "      <td>57.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1230</td>\n",
       "      <td>C</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>19724</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>0.5</td>\n",
       "      <td>219.0</td>\n",
       "      <td>3.93</td>\n",
       "      <td>22.0</td>\n",
       "      <td>663.0</td>\n",
       "      <td>45.00</td>\n",
       "      <td>75.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4184</td>\n",
       "      <td>C</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>11839</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.5</td>\n",
       "      <td>320.0</td>\n",
       "      <td>3.54</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1243.0</td>\n",
       "      <td>122.45</td>\n",
       "      <td>80.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2090</td>\n",
       "      <td>D</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>16467</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.7</td>\n",
       "      <td>255.0</td>\n",
       "      <td>3.74</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>77.50</td>\n",
       "      <td>58.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2105</td>\n",
       "      <td>D</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>21699</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.9</td>\n",
       "      <td>486.0</td>\n",
       "      <td>3.54</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>108.50</td>\n",
       "      <td>109.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   N_Days Status     Drug    Age Sex Ascites Hepatomegaly Spiders Edema  \\\n",
       "0    2221      C  Placebo  18499   F       N            Y       N     N   \n",
       "1    1230      C  Placebo  19724   M       Y            N       Y     N   \n",
       "2    4184      C  Placebo  11839   F       N            N       N     N   \n",
       "3    2090      D  Placebo  16467   F       N            N       N     N   \n",
       "4    2105      D  Placebo  21699   F       N            Y       N     N   \n",
       "\n",
       "   Bilirubin  Cholesterol  Albumin  Copper  Alk_Phos    SGOT  Tryglicerides  \\\n",
       "0        0.5        149.0     4.04   227.0     598.0   52.70           57.0   \n",
       "1        0.5        219.0     3.93    22.0     663.0   45.00           75.0   \n",
       "2        0.5        320.0     3.54    51.0    1243.0  122.45           80.0   \n",
       "3        0.7        255.0     3.74    23.0    1024.0   77.50           58.0   \n",
       "4        1.9        486.0     3.54    74.0    1052.0  108.50          109.0   \n",
       "\n",
       "   Platelets  Prothrombin  Stage  \n",
       "0      256.0          9.9      1  \n",
       "1      220.0         10.8      2  \n",
       "2      225.0         10.0      2  \n",
       "3      151.0         10.2      2  \n",
       "4      151.0         11.5      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(DATA_PATH)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Status', 'Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema']\n",
      "{'Status': 3, 'Drug': 2, 'Sex': 2, 'Ascites': 2, 'Hepatomegaly': 2, 'Spiders': 2, 'Edema': 3}\n"
     ]
    }
   ],
   "source": [
    "object_cols=[col for col in data_df.columns if data_df[col].dtype==\"object\"]\n",
    "number_of_unique={col:len(data_df[col].unique()) for col in object_cols}\n",
    "\n",
    "print(object_cols)\n",
    "print(number_of_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "ord = OrdinalEncoder()\n",
    "\n",
    "cols_for_ordinal = [\"Status\", \"Sex\"]\n",
    "cols_for_ohe = [\"Drug\", \"Ascites\", \"Hepatomegaly\", \"Spiders\", \"Edema\"]\n",
    "\n",
    "ord_result  = ord.fit_transform(data_df[cols_for_ordinal])\n",
    "ohe_result = ohe.fit_transform(data_df[cols_for_ohe])\n",
    "\n",
    "columns_ohe = ohe.get_feature_names_out(cols_for_ohe)\n",
    "\n",
    "ord_df = pd.DataFrame(ord_result, columns=cols_for_ordinal)\n",
    "ohe_df = pd.DataFrame(ohe_result.toarray(), columns=columns_ohe)\n",
    "\n",
    "data_df = pd.concat([data_df, ohe_df], axis=1).drop(columns=cols_for_ohe)\n",
    "data_df[cols_for_ordinal] = ord_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = data_df.drop(TARGET_COL, axis=1).values, data_df[TARGET_COL].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        y = self.targets[idx]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 3\n"
     ]
    }
   ],
   "source": [
    "train_x = torch.from_numpy(train_x).float()\n",
    "train_y = torch.from_numpy(train_y).long()\n",
    "\n",
    "num_class = len(np.unique(train_y))\n",
    "print(f\"Number of classes: {num_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TabDataset(train_x, train_y)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.query = nn.Linear(input_dim, input_dim)\n",
    "        self.key = nn.Linear(input_dim, input_dim)\n",
    "        self.value = nn.Linear(input_dim, input_dim)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Ensure x has three dimensions: (batch_size, sequence_length, features)\n",
    "        if x.dim() < 3:\n",
    "            x = x.unsqueeze(1)  # Example adjustment, depends on expected input shape\n",
    "\n",
    "        queries = self.query(x)\n",
    "        keys = self.key(x)\n",
    "        values = self.value(x)\n",
    "\n",
    "        # Ensure keys are transposed correctly for batch matrix multiplication\n",
    "        keys_transposed = keys.transpose(1, 2)\n",
    "\n",
    "        # Perform batch matrix multiplication\n",
    "        scores = torch.bmm(queries, keys_transposed) / (self.input_dim ** 0.5)\n",
    "        attention = self.softmax(scores)\n",
    "        weighted = torch.bmm(attention, values)\n",
    "        return weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentiveMLP(nn.Module):\n",
    "  def __init__(self, input_dim, num_class):\n",
    "    super(AttentiveMLP, self).__init__()\n",
    "    self.fc1 = nn.Linear(input_dim, 512)\n",
    "    self.fc2 = nn.Linear(512, 256)\n",
    "    self.fc3 = nn.Linear(256, 128),\n",
    "    self.fc4 = nn.Linear(128, num_class)\n",
    "\n",
    "    self.att1 = SelfAttention(512)\n",
    "    self.att2 = SelfAttention(128)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = self.att1(x)\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.att2(x)\n",
    "    x = F.relu(self.fc3(x))\n",
    "    x = self.fc4(x)\n",
    "    x = F.softmax(x, dim=1)\n",
    "    return x, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 24\n",
    "\n",
    "model = AttentiveMLP(input_size, num_class)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs, _ = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
